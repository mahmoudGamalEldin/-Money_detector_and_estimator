{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sound API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sound playing function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def number_reader(number_string):\n",
    "    file_name = \"audio-numbers\\\\\" + number_string + \".wav\"\n",
    "    print(file_name)\n",
    "    wf = wave.open(file_name, 'rb')\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    def callback(in_data, frame_count, time_info, status):\n",
    "        data = wf.readframes(frame_count)\n",
    "        return (data, pyaudio.paContinue)\n",
    "\n",
    "    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels=wf.getnchannels(),\n",
    "                    rate=wf.getframerate(),\n",
    "                    output=True,\n",
    "                    stream_callback=callback)\n",
    "\n",
    "    stream.start_stream()\n",
    "\n",
    "    while stream.is_active():\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    wf.close()\n",
    "\n",
    "    p.terminate()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number division function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def number_reader_api(number):\n",
    "    if number < 100 :\n",
    "        number_reader(str(number))\n",
    "        return None\n",
    "    elif ((number >= 100) and (number < 1000)):\n",
    "        hund = int(100 * np.floor(number/100))\n",
    "        rest =  int(number - hund )\n",
    "        number_reader(str(hund))\n",
    "        number_reader(\"and\")\n",
    "        number_reader(str(rest))  \n",
    "        return None\n",
    "    elif(number >= 1000) and (number < 10000):\n",
    "        thousand = int(1000 *  np.floor(number/1000))\n",
    "        rest1 = int( (number - thousand ))\n",
    "        hund =int( 100 *  np.floor(rest1/100))\n",
    "        rest = int( (rest1 - hund ))\n",
    "        number_reader(str(thousand))\n",
    "        number_reader(\"and\")\n",
    "        number_reader(str(hund))\n",
    "        number_reader(\"and\")\n",
    "        number_reader(str(rest))  \n",
    "        return None\n",
    "    else :\n",
    "        number_reader(str(10000))\n",
    "        return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-numbers\\5000.wav\n",
      "audio-numbers\\and.wav\n",
      "audio-numbers\\500.wav\n",
      "audio-numbers\\and.wav\n",
      "audio-numbers\\55.wav\n"
     ]
    }
   ],
   "source": [
    "number_reader_api(5555)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class our_templates:\n",
    "    templates_values = []\n",
    "    num_of_templates = 0 \n",
    "    templates_list  =[]\n",
    "    #add any new templates here\n",
    "    def __init__(self):\n",
    "        \n",
    "        half_pound_front=cv2.imread('dataset//templates//half_pound_coin_front.png',0)\n",
    "        self.templates_list.append(half_pound_front)\n",
    "        self.templates_values.append(0.5)\n",
    "        \n",
    "        half_pound_back=cv2.imread('dataset//templates//half_pound_coin_back.png',0)\n",
    "        self.templates_list.append(half_pound_back)\n",
    "        self.templates_values.append(0.5)\n",
    "        \n",
    "        one_pound_back=cv2.imread('dataset//templates//one_pound_coin_back.png',0)\n",
    "        self.templates_list.append(one_pound_back)\n",
    "        self.templates_values.append(1)\n",
    "        \n",
    "        one_pound_front=cv2.imread('dataset//templates//one_pound_coin_front.png',0)\n",
    "        self.templates_list.append(one_pound_front)\n",
    "        self.templates_values.append(1)\n",
    "\n",
    "        one_pound_back_paper=cv2.imread('dataset//templates//one_pound_paper_back.png',0)\n",
    "        self.templates_list.append(one_pound_back_paper)\n",
    "        self.templates_values.append(1)\n",
    "        \n",
    "        one_pound_front_paper=cv2.imread('dataset//templates//one_pound_paper_front.png',0)\n",
    "        self.templates_list.append(one_pound_front_paper)\n",
    "        self.templates_values.append(1)      \n",
    "        \n",
    "        five_pound_front_paper=cv2.imread('dataset//templates//5 part_1.jpg',0)\n",
    "        self.templates_list.append(five_pound_front_paper)\n",
    "        self.templates_values.append(5)\n",
    "        \n",
    "        five_pound_back_paper=cv2.imread('dataset//templates//five_pound_paper_back.jpg',0)\n",
    "        self.templates_list.append(five_pound_back_paper)\n",
    "        self.templates_values.append(5)\n",
    "        \n",
    "                \n",
    "        ten_pound_front=cv2.imread('dataset//templates//ten_pound_front.jpg',0)\n",
    "        self.templates_list.append(ten_pound_front)\n",
    "        self.templates_values.append(10)\n",
    "        \n",
    "                        \n",
    "        ten_pound_back=cv2.imread('dataset//templates//ten_pound_back.png',0)\n",
    "        self.templates_list.append(ten_pound_back)\n",
    "        self.templates_values.append(10)\n",
    "        \n",
    "        twenty_pound_front=cv2.imread('dataset//templates//20 front.jpg',0)\n",
    "        self.templates_list.append(twenty_pound_front)\n",
    "        self.templates_values.append(20)\n",
    "        \n",
    "                        \n",
    "        twenty_pound_back=cv2.imread('dataset//templates//20 back.jpg',0)\n",
    "        self.templates_list.append(twenty_pound_back)\n",
    "        self.templates_values.append(20)\n",
    "        \n",
    "        fifty_pound_front=cv2.imread('dataset//templates//50 front.jpg',0)\n",
    "        self.templates_list.append(twenty_pound_front)\n",
    "        self.templates_values.append(50)\n",
    "        \n",
    "                        \n",
    "        fifty_pound_back=cv2.imread('dataset//templates//50_pound_back.jpg',0)\n",
    "        self.templates_list.append(twenty_pound_back)\n",
    "        self.templates_values.append(50)\n",
    "        \n",
    "        hundred_pound_front=cv2.imread('dataset//templates//hundred_front.jpg',0)\n",
    "        self.templates_list.append(hundred_pound_front)\n",
    "        self.templates_values.append(100)\n",
    "\n",
    "        hundred_pound_back=cv2.imread('dataset//templates//hundred_back.jpg',0)\n",
    "        self.templates_list.append(hundred_pound_back)\n",
    "        self.templates_values.append(100)\n",
    "        \n",
    "        two_hundred_pound_front=cv2.imread('dataset//templates//200 front.jpg',0)\n",
    "        self.templates_list.append(two_hundred_pound_front)\n",
    "        self.templates_values.append(200)\n",
    "\n",
    "        two_hundred_pound_back=cv2.imread('dataset//templates//200 back.jpg',0)\n",
    "        self.templates_list.append(two_hundred_pound_back)\n",
    "        self.templates_values.append(200)\n",
    "        \n",
    "        \n",
    "        self.num_of_templates = len(self.templates_values)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(gray,127,255,0)\n",
    "    _,contours,_ = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    c = max(contours, key = cv2.contourArea)\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    #crop the banknote\n",
    "    img_2=img[y:y+h,x:x+w]\n",
    "    img_2=cv2.cvtColor(img_2, cv2.COLOR_BGR2GRAY)\n",
    "    #apply adaptive histogram equalization\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl1 = clahe.apply(img_2)\n",
    "    \n",
    "    \n",
    "    return cl1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## mobile camera test\n",
    "samples_list = []\n",
    "#five samples\n",
    "\n",
    "five1 =cv2.imread('dataset//five_samples//five1.png')\n",
    "five1=preprocess(five1)\n",
    "samples_list.append(five1)\n",
    "\n",
    "five2 =cv2.imread('dataset//five_samples//five2.png')\n",
    "five2=preprocess(five2)\n",
    "samples_list.append(five2)\n",
    "\n",
    "\n",
    "five3 =cv2.imread('dataset//five_samples//five3.png')\n",
    "five3=preprocess(five3)\n",
    "samples_list.append(five3)\n",
    "\n",
    "five4 =cv2.imread('dataset//five_samples//five4.png')\n",
    "five4=preprocess(five4)\n",
    "samples_list.append(five4)\n",
    "\n",
    "\n",
    "ten_1=cv2.imread('dataset//ten_samples//ten1.jpg')\n",
    "ten_1=preprocess(ten_1)\n",
    "samples_list.append(ten_1)\n",
    "\n",
    "\n",
    "ten_2=cv2.imread('dataset//ten_samples//ten2.jpg')\n",
    "ten_2=preprocess(ten_2)\n",
    "samples_list.append(ten_2)\n",
    "\n",
    "\n",
    "ten_3=cv2.imread('dataset//ten_samples//ten3.jpg')\n",
    "ten_3=preprocess(ten_3)\n",
    "samples_list.append(ten_3)\n",
    "\n",
    "\n",
    "ten_4=cv2.imread('dataset//ten_samples//ten4.png')\n",
    "ten_4=preprocess(ten_4)\n",
    "samples_list.append(ten_4)\n",
    "\n",
    "ten_5 =cv2.imread('images//ten_pound_front.jpg')\n",
    "ten_5=preprocess(ten_5)\n",
    "samples_list.append(ten_5)\n",
    "\n",
    "\n",
    "#hundred_1 =cv2.imread('dataset//hundred samples//front_1.png')\n",
    "#samples_list.append(hundred_1)\n",
    "\n",
    "\n",
    "#hundred_2 =cv2.imread('dataset//hundred samples//front_2.jpg')\n",
    "#samples_list.append(hundred_2)\n",
    "\n",
    "#hundred_3 =cv2.imread('dataset//hundred samples//back_1.jpg')\n",
    "#samples_list.append(hundred_3)\n",
    "\n",
    "\n",
    "#hundred_4 =cv2.imread('dataset//hundred samples//back_2.jpg')\n",
    "#samples_list.append(hundred_4)\n",
    "\n",
    "\n",
    "\n",
    "num_of_samples = len(samples_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this function is applied on each template , to get its featues ,, \n",
    "then we could match it with any input image that will be tested\n",
    "\"\"\"\n",
    "def get_currency_feature(img):\n",
    "    #to ensure that image is in gray scale\n",
    "   # img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #declaring orb object\n",
    "    orb=cv2.ORB_create()\n",
    "    #find key points with ORB\n",
    "    kp = orb.detect(img,None)\n",
    "    # compute the descriptors with ORB\n",
    "    kp, des = orb.compute(img, kp)\n",
    "    \n",
    "    return kp, des\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys_and_des = []\n",
    "\n",
    "for i in range(0,num_of_samples):\n",
    "    keys_and_des.append( get_currency_feature(samples_list[i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "templatess = our_templates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def guess(template_image, input_Kp, input_des): #kp,des of the input image , x is the images/\n",
    "    template_kp,template_des=get_currency_feature(template_image)\n",
    "    # create BFMatcher object\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    # Match descriptors.\n",
    "    matches = bf.match(input_des, template_des)\n",
    "    # Sort them in the order of their distance.\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    sum_of_matches=0 \n",
    "    \n",
    "    n_of_matches = 10\n",
    "    length=len(matches)\n",
    "    print (\"length\",length)\n",
    "    for i in range (0 , n_of_matches):\n",
    "        sum_of_matches = sum_of_matches+ matches[i].distance  # getting list of top 10 matches' distances\n",
    "    return  sum_of_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def estimate( input_kp, input_des , templates):\n",
    "    overall_matches=[] \n",
    "    for i in range(0 ,18):  #templates.num_of_templates\n",
    "        overall_matches.append( guess(templates.templates_list[i] ,input_kp , input_des )  )\n",
    "    minimum_dis = overall_matches.index(min(overall_matches)) #getting index of the predicted banknote\n",
    "    \n",
    "    predicted = templates.templates_values[minimum_dis]\n",
    "#    print (overall_matches)\n",
    "    print(\"preddicted = {0} ,index = {1}\".format(predicted , minimum_dis))\n",
    "    print (\"________________________________________________________________________________\")\n",
    "    return predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('length', 255)\n",
      "('length', 252)\n",
      "('length', 272)\n",
      "('length', 249)\n",
      "('length', 181)\n",
      "('length', 152)\n",
      "('length', 222)\n",
      "('length', 184)\n",
      "('length', 216)\n",
      "('length', 241)\n",
      "('length', 229)\n",
      "('length', 237)\n",
      "('length', 229)\n",
      "('length', 237)\n",
      "('length', 212)\n",
      "('length', 240)\n",
      "('length', 222)\n",
      "('length', 248)\n",
      "preddicted = 5 ,index = 6\n",
      "________________________________________________________________________________\n",
      "('length', 263)\n",
      "('length', 251)\n",
      "('length', 272)\n",
      "('length', 244)\n",
      "('length', 173)\n",
      "('length', 144)\n",
      "('length', 234)\n",
      "('length', 180)\n",
      "('length', 211)\n",
      "('length', 239)\n",
      "('length', 235)\n",
      "('length', 243)\n",
      "('length', 235)\n",
      "('length', 243)\n",
      "('length', 208)\n",
      "('length', 241)\n",
      "('length', 219)\n",
      "('length', 252)\n",
      "preddicted = 5 ,index = 6\n",
      "________________________________________________________________________________\n",
      "('length', 269)\n",
      "('length', 256)\n",
      "('length', 276)\n",
      "('length', 255)\n",
      "('length', 184)\n",
      "('length', 146)\n",
      "('length', 221)\n",
      "('length', 179)\n",
      "('length', 204)\n",
      "('length', 242)\n",
      "('length', 235)\n",
      "('length', 239)\n",
      "('length', 235)\n",
      "('length', 239)\n",
      "('length', 204)\n",
      "('length', 235)\n",
      "('length', 217)\n",
      "('length', 257)\n",
      "preddicted = 5 ,index = 6\n",
      "________________________________________________________________________________\n",
      "('length', 142)\n",
      "('length', 138)\n",
      "('length', 150)\n",
      "('length', 139)\n",
      "('length', 119)\n",
      "('length', 100)\n",
      "('length', 141)\n",
      "('length', 106)\n",
      "('length', 136)\n",
      "('length', 139)\n",
      "('length', 135)\n",
      "('length', 148)\n",
      "('length', 135)\n",
      "('length', 148)\n",
      "('length', 128)\n",
      "('length', 139)\n",
      "('length', 134)\n",
      "('length', 140)\n",
      "preddicted = 5 ,index = 6\n",
      "________________________________________________________________________________\n",
      "('length', 215)\n",
      "('length', 198)\n",
      "('length', 232)\n",
      "('length', 196)\n",
      "('length', 158)\n",
      "('length', 148)\n",
      "('length', 241)\n",
      "('length', 172)\n",
      "('length', 204)\n",
      "('length', 244)\n",
      "('length', 249)\n",
      "('length', 236)\n",
      "('length', 249)\n",
      "('length', 236)\n",
      "('length', 200)\n",
      "('length', 213)\n",
      "('length', 244)\n",
      "('length', 249)\n",
      "preddicted = 20 ,index = 11\n",
      "________________________________________________________________________________\n",
      "('length', 228)\n",
      "('length', 219)\n",
      "('length', 229)\n",
      "('length', 210)\n",
      "('length', 157)\n",
      "('length', 137)\n",
      "('length', 232)\n",
      "('length', 167)\n",
      "('length', 202)\n",
      "('length', 226)\n",
      "('length', 231)\n",
      "('length', 221)\n",
      "('length', 231)\n",
      "('length', 221)\n",
      "('length', 200)\n",
      "('length', 225)\n",
      "('length', 225)\n",
      "('length', 235)\n",
      "preddicted = 20 ,index = 11\n",
      "________________________________________________________________________________\n",
      "('length', 215)\n",
      "('length', 207)\n",
      "('length', 218)\n",
      "('length', 196)\n",
      "('length', 153)\n",
      "('length', 136)\n",
      "('length', 223)\n",
      "('length', 165)\n",
      "('length', 201)\n",
      "('length', 218)\n",
      "('length', 213)\n",
      "('length', 222)\n",
      "('length', 213)\n",
      "('length', 222)\n",
      "('length', 202)\n",
      "('length', 218)\n",
      "('length', 210)\n",
      "('length', 213)\n",
      "preddicted = 20 ,index = 10\n",
      "________________________________________________________________________________\n",
      "('length', 246)\n",
      "('length', 228)\n",
      "('length', 250)\n",
      "('length', 225)\n",
      "('length', 180)\n",
      "('length', 151)\n",
      "('length', 245)\n",
      "('length', 169)\n",
      "('length', 206)\n",
      "('length', 284)\n",
      "('length', 247)\n",
      "('length', 242)\n",
      "('length', 247)\n",
      "('length', 242)\n",
      "('length', 222)\n",
      "('length', 224)\n",
      "('length', 242)\n",
      "('length', 243)\n",
      "preddicted = 10 ,index = 9\n",
      "________________________________________________________________________________\n",
      "('length', 208)\n",
      "('length', 198)\n",
      "('length', 211)\n",
      "('length', 195)\n",
      "('length', 148)\n",
      "('length', 142)\n",
      "('length', 197)\n",
      "('length', 155)\n",
      "('length', 188)\n",
      "('length', 200)\n",
      "('length', 219)\n",
      "('length', 197)\n",
      "('length', 219)\n",
      "('length', 197)\n",
      "('length', 199)\n",
      "('length', 194)\n",
      "('length', 202)\n",
      "('length', 211)\n",
      "preddicted = 10 ,index = 8\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(0,num_of_samples):\n",
    "    estimate(keys_and_des[i][0] , keys_and_des[i][1] , templatess)\n",
    "templatess.num_of_samples=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
