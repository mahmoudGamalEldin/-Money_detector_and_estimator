{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot (image):\n",
    "    #plt.imshow(image , 'gray')\n",
    "    plt.imshow(image )\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class our_templates:\n",
    "    templates_values = []\n",
    "    num_of_templates = 0 \n",
    "    templates_list  =[]\n",
    "    #add any new templates here\n",
    "    def __init__(self):\n",
    "        \n",
    "        half_pound_front=cv2.imread('dataset//templates//half_pound_coin_front.png',0)\n",
    "        self.templates_list.append(half_pound_front)\n",
    "        self.templates_values.append(0.5)\n",
    "        \n",
    "        half_pound_back=cv2.imread('dataset//templates//half_pound_coin_back.png',0)\n",
    "        self.templates_list.append(half_pound_back)\n",
    "        self.templates_values.append(0.5)\n",
    "        \n",
    "        one_pound_back=cv2.imread('dataset//templates//one_pound_coin_back.png',0)\n",
    "        self.templates_list.append(one_pound_back)\n",
    "        self.templates_values.append(1)\n",
    "        \n",
    "        one_pound_front=cv2.imread('dataset//templates//one_pound_coin_front.png',0)\n",
    "        self.templates_list.append(one_pound_front)\n",
    "        self.templates_values.append(1)\n",
    "\n",
    "        one_pound_back_paper=cv2.imread('dataset//templates//one_pound_paper_back.png',0)\n",
    "        self.templates_list.append(one_pound_back_paper)\n",
    "        self.templates_values.append(1)\n",
    "        \n",
    "        one_pound_front_paper=cv2.imread('dataset//templates//one_pound_paper_front.png',0)\n",
    "        self.templates_list.append(one_pound_front_paper)\n",
    "        self.templates_values.append(1)      \n",
    "        \n",
    "        five_pound_front_paper=cv2.imread('dataset//templates//five_pound_paper_front.jpg',0)\n",
    "        self.templates_list.append(five_pound_front_paper)\n",
    "        self.templates_values.append(5)\n",
    "        \n",
    "        five_pound_back_paper=cv2.imread('dataset//templates//five_pound_paper_back.jpg',0)\n",
    "        self.templates_list.append(five_pound_back_paper)\n",
    "        self.templates_values.append(5)\n",
    "        \n",
    "                \n",
    "        ten_pound_front=cv2.imread('dataset//templates//ten_pound_front.jpg',0)\n",
    "        self.templates_list.append(ten_pound_front)\n",
    "        self.templates_values.append(10)\n",
    "        \n",
    "                        \n",
    "        ten_pound_back=cv2.imread('dataset//templates//ten_pound_back.jpg',0)\n",
    "        self.templates_list.append(ten_pound_back)\n",
    "        self.templates_values.append(10)\n",
    "        \n",
    "        twenty_pound_front=cv2.imread('dataset//templates//twenty_pound_front.jpg',0)\n",
    "        self.templates_list.append(twenty_pound_front)\n",
    "        self.templates_values.append(20)\n",
    "        \n",
    "                        \n",
    "        twenty_pound_back=cv2.imread('dataset//templates//twenty_pound_back.png',0)\n",
    "        self.templates_list.append(twenty_pound_back)\n",
    "        self.templates_values.append(20)\n",
    "        \n",
    "        fifty_pound_front=cv2.imread('dataset//templates//fifty_pound_front.jpg',0)\n",
    "        self.templates_list.append(twenty_pound_front)\n",
    "        self.templates_values.append(50)\n",
    "        \n",
    "                        \n",
    "        fifty_pound_back=cv2.imread('dataset//templates//fifty_pound_back.jpg',0)\n",
    "        self.templates_list.append(twenty_pound_back)\n",
    "        self.templates_values.append(50)\n",
    "        \n",
    "        hundred_pound_front=cv2.imread('dataset//templates//hundred_front.jpg',0)\n",
    "        self.templates_list.append(hundred_pound_front)\n",
    "        self.templates_values.append(100)\n",
    "\n",
    "        hundred_pound_back=cv2.imread('dataset//templates//hundred_back.jpg',0)\n",
    "        self.templates_list.append(hundred_pound_back)\n",
    "        self.templates_values.append(100)\n",
    "        \n",
    "        two_hundred_pound_front=cv2.imread('dataset//templates//two_hundred_pound_front.png',0)\n",
    "        self.templates_list.append(two_hundred_pound_front)\n",
    "        self.templates_values.append(200)\n",
    "\n",
    "        two_hundred_pound_back=cv2.imread('dataset//templates//two_hundred_pound_back.jpg',0)\n",
    "        self.templates_list.append(two_hundred_pound_back)\n",
    "        self.templates_values.append(200)\n",
    "        \n",
    "        \n",
    "        self.num_of_templates = len(self.templates_values)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mobile camera test\n",
    "samples_list = []\n",
    "sample_values = []\n",
    "#five samples\n",
    "\n",
    "\n",
    "five1 =cv2.imread('dataset//five_samples//five1.png')\n",
    "five1=preprocess(five1)\n",
    "samples_list.append(five1)\n",
    "sample_values.append(5)\n",
    "\n",
    "five2 =cv2.imread('dataset//five_samples//five2.png')\n",
    "five2=preprocess(five2)\n",
    "samples_list.append(five2)\n",
    "sample_values.append(5)\n",
    "\n",
    "five3 =cv2.imread('dataset//five_samples//five3.png')\n",
    "five3=preprocess(five3)\n",
    "samples_list.append(five3)\n",
    "sample_values.append(5)\n",
    "\n",
    "five4 =cv2.imread('dataset//five_samples//five4.png')\n",
    "five4=preprocess(five4)\n",
    "samples_list.append(five4)\n",
    "sample_values.append(5)\n",
    "\n",
    "\"\"\"\n",
    "ten_1=cv2.imread('dataset//ten_samples//ten1.jpg')\n",
    "ten_1=preprocess(ten_1)\n",
    "samples_list.append(ten_1)\n",
    "\n",
    "\n",
    "ten_2=cv2.imread('dataset//ten_samples//ten2.jpg')\n",
    "ten_2=preprocess(ten_2)\n",
    "samples_list.append(ten_2)\n",
    "\n",
    "\n",
    "ten_3=cv2.imread('dataset//ten_samples//ten3.jpg')\n",
    "ten_3=preprocess(ten_3)\n",
    "samples_list.append(ten_3)\n",
    "\n",
    "\n",
    "ten_4=cv2.imread('dataset//ten_samples//ten4.png')\n",
    "ten_4=preprocess(ten_4)\n",
    "samples_list.append(ten_4)\n",
    "\n",
    "ten_5 =cv2.imread('images//ten_pound_front.jpg')\n",
    "ten_5=preprocess(ten_5)\n",
    "samples_list.append(ten_5)\n",
    "\"\"\"\n",
    "\n",
    "hundred_sample =cv2.imread('dataset//hun_sample.jpg',0)\n",
    "samples_list.append(hundred_sample)\n",
    "sample_values.append(100)\n",
    "\n",
    "#hundred_1 =cv2.imread('dataset//hundred samples//front_1.png')\n",
    "#samples_list.append(hundred_1)\n",
    "\n",
    "\n",
    "#hundred_2 =cv2.imread('dataset//hundred samples//front_2.jpg')\n",
    "#samples_list.append(hundred_2)\n",
    "\n",
    "#hundred_3 =cv2.imread('dataset//hundred samples//back_1.jpg')\n",
    "#samples_list.append(hundred_3)\n",
    "\n",
    "\n",
    "#hundred_4 =cv2.imread('dataset//hundred samples//back_2.jpg')\n",
    "#samples_list.append(hundred_4)\n",
    "\n",
    "\n",
    "\n",
    "num_of_samples = len(samples_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this function is applied on each template , to get its featues ,, \n",
    "then we could match it with any input image that will be tested\n",
    "\"\"\"\n",
    "def get_currency_feature(img):\n",
    "    #to ensure that image is in gray scale\n",
    "   # img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #declaring orb object\n",
    "    orb=cv2.ORB_create()\n",
    "    #find key points with ORB\n",
    "    kp = orb.detect(img,None)\n",
    "    # compute the descriptors with ORB\n",
    "    kp, des = orb.compute(img, kp)\n",
    "    \n",
    "    return kp, des\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input image is BGR , loaded by opencv\n",
    "\"\"\"\n",
    "def preprocess(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(gray,127,255,0)\n",
    "    _,contours,_ = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    c = max(contours, key = cv2.contourArea)\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    #crop the banknote\n",
    "    img_2=img[y:y+h,x:x+w]\n",
    "    img_2=cv2.cvtColor(img_2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #apply adaptive histogram equalization\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl1 = clahe.apply(img_2)\n",
    "    \n",
    "    \n",
    "    return cl1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "guess() takes a template and picture's keys and discribtors , runs a brute force matching and gets sum of \n",
    "least 10 distances of matches between them\n",
    "\"\"\"\n",
    "def guess(template_image, input_Kp, input_des): \n",
    "    template_kp,template_des=get_currency_feature(template_image)\n",
    "    # create BFMatcher object\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    # Match descriptors.\n",
    "    matches = bf.match(input_des, template_des)\n",
    "    # Sort them in the order of their distance.\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    sum_of_matches=0 \n",
    "    \n",
    "    n_of_matches = 40 #umber of shortest matches taken into account\n",
    "    length=len(matches)\n",
    "   \n",
    "    for i in range (0 , n_of_matches):\n",
    "        sum_of_matches = sum_of_matches+ matches[i].distance  # getting list of top 10 matches' distances\n",
    "    print (\"length = {0}  and sum_of_matches ={1}\".format(length , sum_of_matches))\n",
    "    return  sum_of_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "estimate () , takes the input pic's keys and discribtors to be tested  , and a group of templates \n",
    ", runs the guess() function against each template and gets sum of smallest 10 distances \n",
    "and the minimum one gets the prediction \n",
    "\"\"\"\n",
    "def estimate( input_kp, input_des , templates):\n",
    "    overall_matches=[] \n",
    "    for i in range(0 ,templates.num_of_templates):  #templates.num_of_templates\n",
    "        overall_matches.append( guess(templates.templates_list[i] ,input_kp , input_des )  )\n",
    "    minimum_dis = overall_matches.index(min(overall_matches)) #getting index of the predicted banknote\n",
    "    \n",
    "    predicted = templates.templates_values[minimum_dis]\n",
    "#    print (overall_matches)\n",
    "    print(\"predicted = {0} ,index = {1}\".format(predicted , minimum_dis))\n",
    "    print (\"________________________________________________________________________________\")\n",
    "    return predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "templatess = our_templates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_and_des = []\n",
    "\n",
    "\n",
    "for i in range(0,num_of_samples):\n",
    "    keys_and_des.append( get_currency_feature(samples_list[i]) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length = 257  and sum_of_matches =2448.0\n",
      "length = 250  and sum_of_matches =2217.0\n",
      "length = 276  and sum_of_matches =2369.0\n",
      "length = 246  and sum_of_matches =2393.0\n",
      "length = 182  and sum_of_matches =2466.0\n",
      "length = 147  and sum_of_matches =2340.0\n",
      "length = 222  and sum_of_matches =2125.0\n",
      "length = 178  and sum_of_matches =2382.0\n",
      "length = 250  and sum_of_matches =2092.0\n",
      "length = 227  and sum_of_matches =2162.0\n",
      "length = 216  and sum_of_matches =2125.0\n",
      "length = 254  and sum_of_matches =2240.0\n",
      "length = 216  and sum_of_matches =2125.0\n",
      "length = 254  and sum_of_matches =2240.0\n",
      "length = 208  and sum_of_matches =2471.0\n",
      "length = 277  and sum_of_matches =2292.0\n",
      "length = 230  and sum_of_matches =2289.0\n",
      "length = 219  and sum_of_matches =2299.0\n",
      "predicted = 10 ,index = 8\n",
      "________________________________________________________________________________\n",
      "FAILED >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "length = 230  and sum_of_matches =2281.0\n",
      "length = 230  and sum_of_matches =2077.0\n",
      "length = 260  and sum_of_matches =2322.0\n",
      "length = 223  and sum_of_matches =2245.0\n",
      "length = 182  and sum_of_matches =2251.0\n",
      "length = 141  and sum_of_matches =2134.0\n",
      "length = 227  and sum_of_matches =2021.0\n",
      "length = 169  and sum_of_matches =2125.0\n",
      "length = 249  and sum_of_matches =1856.0\n",
      "length = 239  and sum_of_matches =2044.0\n",
      "length = 226  and sum_of_matches =1733.0\n",
      "length = 260  and sum_of_matches =2029.0\n",
      "length = 226  and sum_of_matches =1733.0\n",
      "length = 260  and sum_of_matches =2029.0\n",
      "length = 200  and sum_of_matches =2271.0\n",
      "length = 262  and sum_of_matches =2122.0\n",
      "length = 240  and sum_of_matches =1995.0\n",
      "length = 228  and sum_of_matches =2008.0\n",
      "predicted = 20 ,index = 10\n",
      "________________________________________________________________________________\n",
      "FAILED >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "length = 221  and sum_of_matches =2425.0\n",
      "length = 223  and sum_of_matches =2200.0\n",
      "length = 240  and sum_of_matches =2405.0\n",
      "length = 234  and sum_of_matches =2572.0\n",
      "length = 170  and sum_of_matches =2382.0\n",
      "length = 153  and sum_of_matches =2144.0\n",
      "length = 252  and sum_of_matches =1963.0\n",
      "length = 186  and sum_of_matches =2200.0\n",
      "length = 259  and sum_of_matches =1942.0\n",
      "length = 245  and sum_of_matches =1967.0\n",
      "length = 233  and sum_of_matches =1766.0\n",
      "length = 276  and sum_of_matches =2052.0\n",
      "length = 233  and sum_of_matches =1766.0\n",
      "length = 276  and sum_of_matches =2052.0\n",
      "length = 200  and sum_of_matches =2174.0\n",
      "length = 272  and sum_of_matches =2284.0\n",
      "length = 254  and sum_of_matches =1962.0\n",
      "length = 253  and sum_of_matches =1976.0\n",
      "predicted = 20 ,index = 10\n",
      "________________________________________________________________________________\n",
      "FAILED >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "length = 261  and sum_of_matches =2513.0\n",
      "length = 230  and sum_of_matches =2241.0\n",
      "length = 265  and sum_of_matches =2326.0\n",
      "length = 260  and sum_of_matches =2383.0\n",
      "length = 183  and sum_of_matches =2398.0\n",
      "length = 139  and sum_of_matches =2274.0\n",
      "length = 245  and sum_of_matches =2222.0\n",
      "length = 169  and sum_of_matches =2453.0\n",
      "length = 235  and sum_of_matches =2040.0\n",
      "length = 232  and sum_of_matches =2264.0\n",
      "length = 210  and sum_of_matches =2041.0\n",
      "length = 258  and sum_of_matches =2246.0\n",
      "length = 210  and sum_of_matches =2041.0\n",
      "length = 258  and sum_of_matches =2246.0\n",
      "length = 193  and sum_of_matches =2435.0\n",
      "length = 260  and sum_of_matches =2490.0\n",
      "length = 222  and sum_of_matches =2260.0\n",
      "length = 224  and sum_of_matches =2217.0\n",
      "predicted = 10 ,index = 8\n",
      "________________________________________________________________________________\n",
      "FAILED >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "length = 236  and sum_of_matches =2756.0\n",
      "length = 216  and sum_of_matches =2600.0\n",
      "length = 242  and sum_of_matches =2500.0\n",
      "length = 228  and sum_of_matches =2775.0\n",
      "length = 155  and sum_of_matches =2631.0\n",
      "length = 132  and sum_of_matches =2440.0\n",
      "length = 206  and sum_of_matches =2206.0\n",
      "length = 143  and sum_of_matches =2378.0\n",
      "length = 196  and sum_of_matches =2238.0\n",
      "length = 193  and sum_of_matches =2168.0\n",
      "length = 178  and sum_of_matches =2104.0\n",
      "length = 226  and sum_of_matches =2299.0\n",
      "length = 178  and sum_of_matches =2104.0\n",
      "length = 226  and sum_of_matches =2299.0\n",
      "length = 180  and sum_of_matches =2430.0\n",
      "length = 232  and sum_of_matches =2489.0\n",
      "length = 197  and sum_of_matches =2279.0\n",
      "length = 203  and sum_of_matches =2222.0\n",
      "predicted = 20 ,index = 10\n",
      "________________________________________________________________________________\n",
      "FAILED >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "pred = 0 \n",
    "for i in range(0,num_of_samples):\n",
    "    pred = estimate(keys_and_des[i][0] , keys_and_des[i][1] , templatess)\n",
    "    if (pred != sample_values[i] ): \n",
    "        print(\"FAILED >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "    else:\n",
    "        print(\"PASSED\")\n",
    "#templatess.num_of_samples=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
